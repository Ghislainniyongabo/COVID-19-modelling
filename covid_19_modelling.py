# -*- coding: utf-8 -*-
"""covid-19_modelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lYVii7MFHxu-ptdO8E4pkG_IaTRX_Y0L

## Machine Learning and Epidiemological Spread of COVID-19
### Ghislain Niyongabo (ghislainniyongabo@aims.ac.za)

#### importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd  
import numpy as np  
import seaborn as sn
import matplotlib.pyplot as plt   
from sklearn.model_selection import train_test_split 
from sklearn import metrics
# %matplotlib inline
from sklearn.ensemble import RandomForestRegressor
import plotly.graph_objects as go
import plotly.express as px
from sklearn import preprocessing
import statsmodels.api as sm
from scipy.stats import pearsonr
 
from sklearn.model_selection import cross_val_score, GridSearchCV

import pydot
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()

#!pip3 install statsmodels



"""# Report data for the COVID-19

### confimered cases time series analysis
"""

data_covid191=pd.read_csv("dataset/confirmed.csv")

data_covid191.head()

data_covid191.describe()



"""### Grouping the data by country"""

data_covid19=data_covid191.groupby(['Country/Region']).sum().reset_index()

data_covid19.head()



"""# Data preparation"""

data_covid19_cleaned1=data_covid19.melt(id_vars=['Country/Region','Lat','Long'],var_name="Date",value_name="Confirmed")

data_covid19_cleaned1['Date']=pd.to_datetime(data_covid19_cleaned1['Date'])

data_covid19_cleaned=data_covid19_cleaned1.groupby(['Country/Region','Date']).sum().reset_index()

"""# Humidity Data"""

humidity=pd.read_csv("dataset/humidity.csv")

humidity.head()



"""#### Viewing the columns in the dataframe - Timeseries"""

humidity.columns

"""### Formatting the dataset"""

data_humidity=humidity.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], 
        var_name="Date", 
        value_name="Humidity")

data_humidity.head()

data_humidity_grouped=data_humidity.groupby(['Country/Region','Date']).mean().reset_index()

data_humidity_grouped.tail()

data_humidity_grouped.shape



"""# Temperature data"""

temperature=pd.read_csv("dataset/temperature.csv")

temperature.head()

"""## Formatting the dataset"""

data_temperature=temperature.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], 
        var_name="Date", 
        value_name="temperature")

data_temperature_grouped=data_temperature.groupby(['Country/Region','Date']).mean().reset_index()

data_temperature_grouped.head()

"""# Wind data"""

wind=pd.read_csv("dataset/wind_speed.csv")

"""#### Formatting the dataset"""

data_wind=wind.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], 
        var_name="Date", 
        value_name="wind")

data_wind_grouped=data_wind.groupby(['Country/Region','Date']).mean().reset_index()

data_wind_grouped.head()

"""# Merging the COVID-19 report with the daily weather conditions"""

#data_covid19_cleaned['Deaths']=data_covid19_death_cleaned1['Deaths']
data_covid19_cleaned['humidity']=data_humidity_grouped['Humidity']
data_covid19_cleaned['temperature']=data_temperature_grouped['temperature']
data_covid19_cleaned['wind']=data_wind_grouped['wind']



data_covid19_cleaned.head()



#data_covid19_cleaned.set_index('Date').head()

data_covid19_cleaned.head()

data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Tunisia') & (data_covid19_cleaned['Date'] == '2020-03-29')]



data_covid19_cleaned_date=data_covid19_cleaned.groupby('Date').sum().reset_index()

data_covid19_cleaned_date.head()

data_covid19_cleaned_date.shape

data_covid19_cleaned_date.loc[(data_covid19_cleaned_date['Date'] == '2020-02-01')]

data_covid19_cleaned_date.loc[(data_covid19_cleaned_date['Date'] == '2020-03-01')]

data_covid19_cleaned_date.loc[(data_covid19_cleaned_date['Date'] == '2020-04-01')]

data_covid19_cleaned_date.head()

"""## Exploratory Analysis

#### For Chart 1 : Total Confirmed Coronavirus Cases (Globally)
"""

# Create figure and plot space
fig, ax = plt.subplots(figsize=(12, 5))

# Add x-axis and y-axis
ax.bar(data_covid19_cleaned_date['Date'],
       data_covid19_cleaned_date['Confirmed'],
       color='purple')

# Set title and labels for axes
ax.set(xlabel="Observation Dates",
       ylabel="The number of confirmed cases")

plt.show()





"""## Vizualizing the datapoints according to the weather conditions"""

data_covid19_cleaned.shape

"""###### Number of confirmed cases vs humidity"""

plt.figure(figsize=(10,5))
plt.plot( data_covid19_cleaned['humidity'],data_covid19_cleaned['Confirmed'], 'bo')
plt.xlabel('Humidity ', fontsize=16)
plt.ylabel('The confirmed cases', fontsize=16)
#plt.title('Time series of the number of confirmed cases')
plt.grid()
plt.show()

"""###### Number of confirmed cases vs temperature"""

plt.figure(figsize=(10,5))
plt.plot( data_covid19_cleaned['temperature'],data_covid19_cleaned['Confirmed'], 'bo')
plt.xlabel('Temperature', fontsize=16)
plt.ylabel('The confirmed cases', fontsize=16)
#plt.title('Time series of the number of confirmed cases')
plt.grid()
plt.show()

"""###### Number of confirmed cases vs wind"""

plt.figure(figsize=(10,5))
plt.plot( data_covid19_cleaned['wind'],data_covid19_cleaned['Confirmed'], 'bo')
plt.xlabel('Wind speed', fontsize=16)
plt.ylabel('The confirmed cases', fontsize=16)
#plt.title('Time series of the number of confirmed cases')
plt.grid()
plt.show()

mask=(data_covid19_cleaned['Country/Region']=='Cote d\'Ivoire') & (data_covid19_cleaned['Date'] >= '2020-01-22') & (data_covid19_cleaned['Date'] <= '2020-03-29') 
country_one = data_covid19_cleaned.loc[mask]
country_one.mean()

"""##### Distribution of the COVID_19 infection cases globally"""

data_vizua=data_covid19_cleaned1.groupby('Country/Region').sum()

date=data_vizua.drop('China').reset_index()

date.head()

#data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Canada') & (data_covid19_cleaned['Date'] == '2020-03-30')]

fig = px.pie(date, values = 'Confirmed',names='Country/Region', height=600)
fig.update_traces(textposition='inside', textinfo='percent+label')

fig.update_layout(
    title_x = 0.5,
    geo=dict(
        showframe = True,
        showcoastlines = True,
    ))
fig.show()
plt.savefig('risk_countries.png')

"""# Data vizualisation for th etop 30 high ranked countries"""

data_covid19_cleaned['Country/Region'].unique()











data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Ghana') & (data_covid19_cleaned['Date'] == '2020-03-15') ]

mask=(data_covid19_cleaned['Country/Region']=='Ghana') & (data_covid19_cleaned['Date'] >= '2020-01-22') & (data_covid19_cleaned['Date'] <= '2020-03-15') 
country_one = data_covid19_cleaned.loc[mask]
country_one.mean()

"""#### Total Confirmed Coronavirus Cases (Africa)"""

plot_Senegal=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Senegal')]
plot_Nigeria=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Nigeria')]
plot_Tunisia=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Tunisia')]
plot_Algeria=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Algeria')]
plot_Egypt=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Egypt')]
plot_South_Africa=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'South Africa')]
plot_cote=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Cote d\'Ivoire')]
plot_Morocco=data_covid19_cleaned.loc[(data_covid19_cleaned['Country/Region'] == 'Morocco')]

plot_Senegal.head()





plt.figure(figsize=(14, 8))
plt.plot(plot_Senegal['Date'], plot_Senegal['Confirmed'])
plt.plot(plot_Nigeria['Date'], plot_Nigeria['Confirmed'])
plt.plot(plot_Tunisia['Date'], plot_Tunisia['Confirmed'])
plt.plot(plot_Algeria['Date'], plot_Algeria['Confirmed'])
plt.plot(plot_Egypt['Date'], plot_Egypt['Confirmed'])
plt.plot(plot_South_Africa['Date'], plot_South_Africa['Confirmed'])
plt.plot(plot_cote['Date'],plot_cote['Confirmed'])
plt.plot(plot_Morocco['Date'], plot_Morocco['Confirmed'])                
#plt.title('# of Coronavirus Cases', size=30)
plt.xlabel('Observation date', size=20)
plt.ylabel('Confirmed cases', size=20)
plt.legend(['Senegal', 'Nigera', 'Tunisia', 'Algeria', 'Egypt', 'South Africa','Cote d\'Ivoire', 'Morocco'])
plt.xticks(size=10)
plt.yticks(size=10)

plt.grid()
plt.show()

"""#### Distribution of the confirmed cases in Africa"""



data_covid_africa=pd.read_csv("dataset/africa_dataset.csv")

data_covid_africa

#sns.catplot(data_covid_africa['Countries'],data_covid_africa['Confirmed_cases'])
import seaborn as sns
sns.catplot(x="Confirmed cases",y="Countries",kind='bar',data=data_covid_africa)



"""# Regression Model for analysis 


By implementing a regression model which tries to use the country input variables to predict the most recent number of infections as target, we can extract the relative feature importance. We will use Random forest and we will look at the impact of different weather conditions (temperature, humidity and wind velocity) and other four variables chosen to support the analysis based on their implications in the outbreak severity.

#### Initially we looked at the global analysis using some the most affected countries and including countries that were high risked to get the outbreak in the early days
"""

dataframe_cov=pd.read_csv("dataset/high_risk_factor_data_temp.csv")

dataframe_cov.head()

"""#### Checking the shape of the sample dataset"""

dataframe_cov.shape

"""#### Checking the nulls"""

dataframe_cov['Total_testing'].isnull().sum()

#dataframe_cov['Total_testing'].fillna(mean)

"""#### Scaling the cumulative number of confirmed cases into logs"""

dataframe_cov['Confirmed_log']=np.log10(dataframe_cov['Confirmed_cases'])

dataframe_cov=dataframe_cov.fillna(0)

"""## Variables association analysis

#### Temperature Vs Confirmed cases
"""

corr, _ = pearsonr(dataframe_cov['Temperature'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Temperature and the number of confirmed cases is: %.3f' % corr)

"""#### ITR Vs Confirmed cases"""

corr, _ = pearsonr(dataframe_cov['Risk'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Risk and the number of confirmed cases is: %.3f' % corr)

"""#### Humidity Vs Confirmed cases"""

corr, _ = pearsonr(dataframe_cov['Humidity'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Humidity and the number of confirmed cases is: %.3f' % corr)

"""#### Wind Vs Confirmed cases"""

corr, _ = pearsonr(dataframe_cov['Wind'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Wind and the number of confirmed cases is: %.3f' % corr)

"""### Population density"""

corr, _ = pearsonr(dataframe_cov['Population density'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Population density and the number of confirmed cases is: %.3f' % corr)

dataframe_cov.columns



#dataframe_final['Confirmed_log']=np.log10(dataframe_final['Confirmed_cases'])

dataframe_cov['Lockdown_date']=pd.to_datetime(dataframe_cov['Lockdown_date'])

date=[]
for i in range(len(dataframe_cov)):
    date.append('2020-01-22')

start_date=pd.DataFrame(date)

dataframe_cov['start_date']=pd.to_datetime(date)

dataframe_cov



dataframe_cov['days']=dataframe_cov['Lockdown_date']-dataframe_cov['start_date']

dataframe_final=dataframe_cov

dataframe_final['days']=dataframe_final['days']/np.timedelta64(1,'D')

dataframe_final.head()

"""#### Lockdown dates Vs Confirmed cases"""

corr, _ = pearsonr(dataframe_cov['days'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Wind and the number of confirmed cases is: %.3f' % corr)

"""#### GDP Vs Confirmed cases"""

corr, _ = pearsonr(dataframe_cov['GDP'], dataframe_cov['Confirmed_log'])
print('The correlation between the variable Temperature and the number of confirmed cases is: %.3f' % corr)

"""## Data pre-processing

### Splitting into Features and Target
"""

Y=dataframe_final['Confirmed_log']
X=dataframe_final[['days','Risk','Temperature','Humidity','Wind','Population density','GDP']].values



"""## Printing the statistics"""



x = sm.add_constant(X)  
model = sm.OLS(Y, x).fit()
predictions = model.predict(x) 
print_model = model.summary()
print(print_model)



"""### Splitting into training and testing dataset"""

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0)

y_test

"""# Tuning  Hypeparameters"""

rfc=RandomForestRegressor(random_state=42)
param_grid = { 
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [i for i in range(3,10)],
    'min_samples_leaf':[i for i in range(3,7)],
}

CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)

CV_rfc.fit(X_train, y_train)
print(CV_rfc)

CV_rfc.best_params_

"""### Modelling process"""

results = []
results1= []
n_estimator_options = [i for i in range(1,750)]
#

for trees in n_estimator_options:
    model= RandomForestRegressor(n_estimators=trees,max_depth=3,oob_score=True, bootstrap=True, random_state=42,max_features= 'sqrt',min_samples_leaf= 6)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    y_pred = y_pred.reshape(-1, 1)

    rep=metrics.mean_squared_error(y_test, y_pred)
    rep1=metrics.mean_absolute_error(y_test, y_pred)
 
    print('MSE: ', rep,trees)
    #print('MAE: ', rep1,trees)
    results.append(rep)
    results1.append(rep1)
    print (" ")

plt.figure(figsize=(7,8))
pd.Series(results, n_estimator_options).plot()
pd.Series(results1, n_estimator_options).plot()
plt.xlabel('The number of tree', size=10)
plt.ylabel('The MSE and MAE', size=10)
plt.legend(['MSE', 'MAE'])
plt.xticks(size=10)
plt.yticks(size=10)
#plt.grid()
plt.show()





"""# Feature evaluation

#### select the best model and compute the feature importance
"""

model= RandomForestRegressor(n_estimators=47,max_depth=3,oob_score=True, bootstrap=True, random_state=42,max_features= 'sqrt',min_samples_leaf= 3)
model.fit(X_train, y_train)


values=model.feature_importances_

"""#### Plot the features"""

valuess=np.array(values)

letter=['days','ITR','Temperature','Humidity','Wind','Population density','GDP']

variable=np.array(letter)

dataframe = pd.DataFrame({'Features': variable.flatten(), 'Importance': valuess.flatten()})
dataframe

sns.catplot(x="Importance",y="Features",kind='bar',data=dataframe)





"""### Africa analysis"""



data_covid_africa=pd.read_csv("dataset/africa_dataset.csv")

date=[]
for i in range(len(data_covid_africa)):
    date.append('2020-01-22')

data_covid_africa['start_date']=pd.to_datetime(date)

data_covid_africa['lockdown date']=pd.to_datetime(data_covid_africa['lockdown date'])

data_covid_africa['Confirmed_log']=np.log10(data_covid_africa['Confirmed cases'])

data_covid_africa.head()

data_covid_africa['days']=data_covid_africa['lockdown date']-data_covid_africa['start_date']
data_covid_africa_cov=data_covid_africa
data_covid_africa_cov['days']=data_covid_africa_cov['days']/np.timedelta64(1,'D')
 
data_covid_africa_cov.head()

"""### Feature and target"""

Y1=data_covid_africa['Confirmed_log']
X1=data_covid_africa[['days','Risk_country','temperature','humidity','wind velocity','population density','GDP_country']].values

"""### Splitting the training and testing set"""

X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.25, random_state=0)



"""## Modelling process"""



results = []
results1= []
n_estimator_options = [i for i in range(1,750)]
#

for trees in n_estimator_options:
    model1= RandomForestRegressor(n_estimators=trees,max_depth=3,oob_score=True, bootstrap=True, random_state=42,max_features= 'sqrt',min_samples_leaf= 6)
    model1.fit(X_train, y_train)

    y_pred = model1.predict(X)
    y_pred = y_pred.reshape(-1, 1)

    rep=metrics.mean_squared_error(Y, y_pred)
    rep1=metrics.mean_absolute_error(Y, y_pred)
 
    print('MSE: ', rep,trees)
    print('MAE: ', rep1,trees)
    results.append(rep)
    results1.append(rep1)
    print (" ")
plt.figure(figsize=(7,8))
pd.Series(results, n_estimator_options).plot()
pd.Series(results1, n_estimator_options).plot()
plt.xlabel('The number of trees', size=10)
plt.ylabel('The MSE and MAE', size=10)
plt.legend(['MSE', 'MAE'])
plt.xticks(size=10)
plt.yticks(size=10)
#plt.grid()
plt.show()



model1= RandomForestRegressor(n_estimators=49,max_depth=3,oob_score=True, random_state=42,max_features= 'sqrt',min_samples_leaf= 6)
model1.fit(X_train1, y_train1)



"""# Feature importance"""

values1=model1.feature_importances_

valuess1=np.array(values1)

variable=np.array(['days','ITR','Temperature','Humidity','Wind velocity','Population density','GDP'])



dataframe1 = pd.DataFrame({'Features': variable.flatten(), 'Importance': valuess1.flatten()})
dataframe1

sns.catplot(x="Importance",y="Features",kind='bar',data=dataframe1)





"""# Predictions"""

y_pred1 = model1.predict(X_test1)
y_pred1 = y_pred1.reshape(-1, 1)

"""# Model Evaluation"""

print("MAE", metrics.mean_absolute_error(y_test1, y_pred1))
print("MSE", metrics.mean_squared_error(y_test1, y_pred1))
#print("RMSE", np.sqrt(metrics.mean_squared_error(y_test1, y_pred1)))







"""# Death analysis"""

dataset_covid_death=pd.read_csv("dataset/deaths.csv")
dataset_covid19_confirmed=pd.read_csv("dataset/confirmed.csv")

data_covid_death=dataset_covid_death.groupby('Country/Region').sum().reset_index()

data_covid_death.tail(10)

data_covid19_confirmed=dataset_covid19_confirmed.groupby('Country/Region').sum().reset_index()

data_covid19_confirmed.tail(10)

data_covid19_confirmed_top=data_covid19_confirmed.nlargest(20, ['4/10/20'])

IFR_dataset=pd.DataFrame(data_covid19_confirmed_top['Lat'])

IFR_dataset['Country']=data_covid19_confirmed['Country/Region']
IFR_dataset['Confirmed_2/10/20']=data_covid19_confirmed['2/10/20']
IFR_dataset['Deaths_2/10/20']=data_covid_death['2/10/20']
IFR_dataset['Confirmed_3/10/20']=data_covid19_confirmed['3/10/20']
IFR_dataset['Deaths_3/10/20']=data_covid_death['3/10/20']
IFR_dataset['Confirmed_4/10/20']=data_covid19_confirmed['4/10/20']
IFR_dataset['Deaths_4/10/20']=data_covid_death['4/10/20']

IFR_dataset.head()

IFR_dataset['IFR_2/10/20']=(IFR_dataset['Deaths_2/10/20'])*100/IFR_dataset['Confirmed_2/10/20']
IFR_dataset['IFR_3/10/20']=(IFR_dataset['Deaths_3/10/20'])*100/IFR_dataset['Confirmed_3/10/20']
IFR_dataset['IFR_4/10/20']=(IFR_dataset['Deaths_4/10/20'])*100/IFR_dataset['Confirmed_4/10/20']

IFR_dataset.head(5)

IFR_dataset.fillna(0)



IFR_dataset.to_csv(r'IFR_dataset.csv', index = False)





"""# Tests analysis"""

testing1=pd.read_csv("dataset/owid-covid-data.csv")

testing1.head()



"""#  Exploratory analysis"""

mask1=(testing1['date'] > '2020-03-01') & (testing1['date'] < '2020-04-10') 
#mask=(testing1['date'] == '2020-04-10') 
testing = testing1.loc[mask1]
country_info=testing.fillna(0)

country_info.head()

country_info.columns



plo_data=country_info.groupby('date').sum().reset_index()

plo_data.head()

plt.figure(figsize=(10,5))
plt.plot(plo_data.index,plo_data['new_cases'])
plt.plot(plo_data.index,plo_data['new_tests'])

plt.show()

fig_1 = go.Figure(data=go.Scatter(x=data_covid19_cleaned_date['Date'], y = data_covid19_cleaned_date['Confirmed'], mode='lines+markers'))
fig_1.update_layout(title='Total Coronavirus Confirmed Cases (Globally)',
                  yaxis_title='Confirmed Cases', xaxis_tickangle = 315 )
fig_1.show()





dataframe_cases=country_info.drop(['new_cases',
       'total_deaths', 'new_deaths', 'total_cases_per_million',
       'new_cases_per_million', 'total_deaths_per_million',
       'new_deaths_per_million', 'total_tests', 'new_tests',
       'total_tests_per_thousand', 'new_tests_per_thousand', 'tests_units'], axis=1).reset_index(drop=True).sum()
dataframe_test=country_info.drop(['iso_code', 'location','total_cases','new_cases',
       'total_deaths', 'new_deaths', 'total_cases_per_million',
       'new_cases_per_million', 'total_deaths_per_million',
       'new_deaths_per_million', 'new_tests',
       'total_tests_per_thousand', 'new_tests_per_thousand', 'tests_units'],axis=1).reset_index(drop=True).sum()

dataframe_global=pd.DataFrame(dataframe_cases.sum())

dataframe_cases.isnull().sum()

dataframe_cases

plot=pd.Series(data=np.array([x1-x2 for (x1,x2) in zip(dataframe_cases,dataframe_test.values)]),index=dataframe_test['date'])



mask=(testing1['date'] == '2020-04-10') 
testing = testing1.loc[mask]
country=testing.fillna(0)





data_covid19_confirmed_top=country.nlargest(100, ['total_tests'])

data_covid19_confirmed_top.to_csv('data_covid19_confirmed_top.csv')

data_frame1=pd.read_csv("data_covid19_confirmed_top.csv")

testing_dataframe=data_frame1.sort_values(by=['location'])

"""## Correlation test"""

corr, _ = pearsonr(testing_dataframe['new_cases'], testing_dataframe['new_tests'])
print('The correlation between the variable Temperature and the number of confirmed cases is: %.3f' % corr)



data_covid19_cleaned.head()

"""### Selecting observations from 2020-03-01 and 2020-04-10"""

mask=(data_covid19_cleaned['Date'] >= '2020-03-01') & (data_covid19_cleaned['Date'] <= '2020-04-10') 
country_one = data_covid19_cleaned.loc[mask]

"""### grouping by country"""

data_grouped=data_covid19_cleaned.groupby('Country/Region').mean().reset_index()



"""### Constructing dataset with the highest testing numbers"""

countries=['Afghanistan', 'Albania', 'Andorra', 'Angola', 'Anguilla',
       'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba',
       'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain',
       'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin',
       'Bermuda', 'Bhutan', 'Bolivia', 'Bonaire Sint Eustatius and Saba',
       'Bosnia and Herzegovina', 'Botswana', 'Brazil', 'Brunei',
       'Bulgaria', 'Burkina Faso', 'Burundi', 'Cameroon', 'Canada',
       'Cape Verde', 'Central African Republic', 'Chile', 'China',
       'Colombia', 'Congo', 'Costa Rica', "Cote d'Ivoire", 'Croatia',
       'Cuba', 'Czech Republic', 'Democratic Republic of Congo',
       'Denmark', 'Ecuador', 'Estonia', 'Finland', 'Ghana', 'Greece',
       'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Israel',
       'Italy', 'Japan', 'Kazakhstan', 'Kenya', 'Latvia', 'Lithuania',
       'Luxembourg', 'Malaysia', 'Mexico', 'Morocco', 'Myanmar', 'Nepal',
       'New Zealand', 'Norway', 'Pakistan', 'Panama', 'Paraguay', 'Peru',
       'Poland', 'Portugal', 'Qatar', 'Romania', 'Russia', 'Rwanda',
       'Senegal', 'Serbia', 'Slovakia', 'Slovenia', 'South Africa',
       'South Korea', 'Switzerland', 'Taiwan', 'Thailand', 'Tunisia',
       'Turkey', 'Uganda', 'Ukraine', 'United Arab Emirates',
       'United Kingdom', 'United States', 'Uruguay', 'Vietnam',
       'Zimbabwe']



total=[]

for i in range(len(data_grouped)):
    #print(data_grouped['Country/Region'][i])
    for k in countries:
        if data_grouped['Country/Region'][i]==k:
            total.append([data_grouped['Country/Region'][i],data_grouped['temperature'][i],data_grouped['humidity'][i],data_grouped['wind'][i]])
            
dataframe= pd.DataFrame (total, columns = ['Country','temperature','humidity','wind'])



dataframe['Country'].unique()



selected_country=['Afghanistan', 'Albania', 'Andorra', 'Angola',
       'Antigua and Barbuda', 'Argentina', 'Armenia', 'Australia',
       'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh',
       'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan',
       'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil',
       'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cameroon',
       'Canada', 'Central African Republic', 'Chile', 'China', 'Colombia',
       'Costa Rica', "Cote d'Ivoire", 'Croatia', 'Cuba', 'Denmark',
       'Ecuador', 'Estonia', 'Finland', 'Ghana', 'Greece', 'Hungary',
       'Iceland', 'India', 'Indonesia', 'Iran', 'Israel', 'Italy',
       'Japan', 'Kazakhstan', 'Kenya', 'Latvia', 'Lithuania',
       'Luxembourg', 'Malaysia', 'Mexico', 'Morocco', 'Nepal',
       'New Zealand', 'Norway', 'Pakistan', 'Panama', 'Paraguay', 'Peru',
       'Poland', 'Portugal', 'Qatar', 'Romania', 'Russia', 'Rwanda',
       'Senegal', 'Serbia', 'Slovakia', 'Slovenia', 'South Africa',
       'Switzerland', 'Thailand', 'Tunisia', 'Turkey', 'Uganda',
       'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uruguay',
       'Vietnam', 'Zimbabwe']

total=[]

for i in range(len(testing_dataframe)):
    #print(data_grouped['Country/Region'][i])
    for k in selected_country:
        if testing_dataframe['location'][i]==k:
            total.append([testing_dataframe['location'][i],testing_dataframe['total_cases'][i],testing_dataframe['total_tests'][i]])
            
dataframe_2= pd.DataFrame (total, columns = ['location','total_cases','total_tests'])

testing_dataset=dataframe_2.sort_values(by=['location']).reset_index()

dataframe.shape

"""### Preparing the dataset for the testing modelling"""

dataframe['total_tests']=testing_dataset['total_tests']
dataframe['total_cases']=testing_dataset['total_cases']

dataframe['Confirmed_log']=np.log10(dataframe['total_cases'])

dataframe.head()



"""# Feature and target  splitting"""

X2=dataframe[['temperature','humidity','wind','total_tests']].values
Y2=dataframe[['Confirmed_log']].values

y2=Y2.ravel()



"""### Training and testing set"""

X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.25, random_state = 1)

"""## Trainin the model"""

regressor = RandomForestRegressor(n_estimators = 1000, random_state = 0   )
regressor.fit( X_train2, y_train2)

"""# Feature importance"""

values=regressor.feature_importances_

values

"""## Predictions"""

y_pred2 = regressor.predict(X_test2)

"""# Evaluating the model"""

print("MAE", metrics.mean_absolute_error(y_test2, y_pred2))
print("MSE", metrics.mean_squared_error(y_test2, y_pred2))
#print("RMSE", np.sqrt(metrics.mean_squared_error(y_test1, y_pred1)))





"""##### Computing the total number of confirmed cases on specific dates"""

pdd=pd.read_csv("dataset/GSSE/time_series_covid19_confirmed_global.csv")

pdd['5/10/20'].sum()

##### Computing the total death cases on specific dates

pd_death=pd.read_csv("dataset/GSSE/time_series_covid19_deaths_global.csv")

pd_death['5/10/20'].sum()

#pdd['Country/Region'].unique()

pd1=pdd.groupby(['Country/Region']).sum().reset_index()

mask=(pd1['Country/Region']=='Morocco')
country_one = pd1.loc[mask]
country_one['3/16/20']



